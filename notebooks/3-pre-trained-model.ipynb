{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertForSequenceClassification\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import AutoTokenizer\n",
    "import ast  # For safely evaluating stringified lists\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from torch.optim import AdamW\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Apple Silicon (MPS)\n"
     ]
    }
   ],
   "source": [
    "# Device Check\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "    print(\"Using Apple Silicon (MPS)\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(f\"Using GPU: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Using CPU (training will be slower)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "MPS backend out of memory (MPS allocated: 18.15 GB, other allocations: 816.00 KB, max allowed: 18.13 GB). Tried to allocate 89.42 MB on private pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[124], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m BertTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbert-base-uncased\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m model \u001b[38;5;241m=\u001b[39m BertForSequenceClassification\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbert-base-uncased\u001b[39m\u001b[38;5;124m\"\u001b[39m, num_labels\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m model\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/transformers/modeling_utils.py:4110\u001b[0m, in \u001b[0;36mPreTrainedModel.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   4105\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dtype_present_in_args:\n\u001b[1;32m   4106\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   4107\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou cannot cast a GPTQ model in a new `dtype`. Make sure to load the model using `from_pretrained` using the desired\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   4108\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m `dtype` by passing the correct `torch_dtype` argument.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   4109\u001b[0m         )\n\u001b[0;32m-> 4110\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1355\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1352\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1353\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[0;32m-> 1355\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_apply(convert)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:915\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    914\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 915\u001b[0m         module\u001b[38;5;241m.\u001b[39m_apply(fn)\n\u001b[1;32m    917\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    918\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    919\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    920\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    925\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    926\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:915\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    914\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 915\u001b[0m         module\u001b[38;5;241m.\u001b[39m_apply(fn)\n\u001b[1;32m    917\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    918\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    919\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    920\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    925\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    926\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:915\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    914\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 915\u001b[0m         module\u001b[38;5;241m.\u001b[39m_apply(fn)\n\u001b[1;32m    917\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    918\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    919\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    920\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    925\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    926\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:942\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    938\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    939\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    940\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    941\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 942\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m fn(param)\n\u001b[1;32m    943\u001b[0m p_should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    945\u001b[0m \u001b[38;5;66;03m# subclasses may have multiple child tensors so we need to use swap_tensors\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1341\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1334\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m   1335\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(\n\u001b[1;32m   1336\u001b[0m             device,\n\u001b[1;32m   1337\u001b[0m             dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1338\u001b[0m             non_blocking,\n\u001b[1;32m   1339\u001b[0m             memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format,\n\u001b[1;32m   1340\u001b[0m         )\n\u001b[0;32m-> 1341\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(\n\u001b[1;32m   1342\u001b[0m         device,\n\u001b[1;32m   1343\u001b[0m         dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1344\u001b[0m         non_blocking,\n\u001b[1;32m   1345\u001b[0m     )\n\u001b[1;32m   1346\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1347\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot copy out of meta tensor; no data!\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: MPS backend out of memory (MPS allocated: 18.15 GB, other allocations: 816.00 KB, max allowed: 18.13 GB). Tried to allocate 89.42 MB on private pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure)."
     ]
    }
   ],
   "source": [
    "# Load tokenizer and model\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=3)\n",
    "model.to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "loss_fn = nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    num_train_epochs=2,\n",
    "    per_device_train_batch_size=4,   # reduced\n",
    "    per_device_eval_batch_size=8,    # reduced\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    logging_steps=10,\n",
    "    save_strategy=\"epoch\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vh/hr9w_0vd1xv4xfslxfhrwmxh0000gn/T/ipykernel_29693/2175986362.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx], dtype=torch.long) for key, val in self.encodings.items()}\n",
      "/var/folders/vh/hr9w_0vd1xv4xfslxfhrwmxh0000gn/T/ipykernel_29693/2175986362.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item['labels'] = torch.tensor(self.labels[idx], dtype=torch.long)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "MPS backend out of memory (MPS allocated: 18.15 GB, other allocations: 816.00 KB, max allowed: 18.13 GB). Tried to allocate 32.00 KB on private pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[126], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m total_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[0;32m----> 5\u001b[0m     input_ids \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong)\n\u001b[1;32m      6\u001b[0m     attention_mask \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong)\n\u001b[1;32m      7\u001b[0m     labels \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: MPS backend out of memory (MPS allocated: 18.15 GB, other allocations: 816.00 KB, max allowed: 18.13 GB). Tried to allocate 32.00 KB on private pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure)."
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "for epoch in range(3):\n",
    "    total_loss = 0\n",
    "    for batch in train_loader:\n",
    "        input_ids = batch['input_ids'].to(device, dtype=torch.long)\n",
    "        attention_mask = batch['attention_mask'].to(device, dtype=torch.long)\n",
    "        labels = batch['labels'].to(device, dtype=torch.long)\n",
    "\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    print(f\"Epoch {epoch + 1} completed. Avg Loss: {avg_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReviewDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = {\n",
    "            key: torch.stack(val).to(torch.int64) for key, val in encodings.items()\n",
    "        }\n",
    "        self.labels = labels.to(torch.long)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            \"input_ids\": self.encodings[\"input_ids\"][idx],\n",
    "            \"attention_mask\": self.encodings[\"attention_mask\"][idx],\n",
    "            \"token_type_ids\": self.encodings[\"token_type_ids\"][idx],\n",
    "            \"labels\": self.labels[idx]\n",
    "        }\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in model.bert.named_parameters():\n",
    "    if \"encoder.layer.0\" in name or \"encoder.layer.1\" in name:\n",
    "        param.requires_grad = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "\n",
    "class ReviewDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx], dtype=torch.long) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "`AcceleratorState` object has no attribute `distributed_type`. This happens if `AcceleratorState._reset_state()` was called and an `Accelerator` or `PartialState` was not reinitialized.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[128], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Train the Model\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m trainer\u001b[38;5;241m.\u001b[39mtrain()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/transformers/trainer.py:2206\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2204\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   2205\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2206\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m inner_training_loop(\n\u001b[1;32m   2207\u001b[0m         args\u001b[38;5;241m=\u001b[39margs,\n\u001b[1;32m   2208\u001b[0m         resume_from_checkpoint\u001b[38;5;241m=\u001b[39mresume_from_checkpoint,\n\u001b[1;32m   2209\u001b[0m         trial\u001b[38;5;241m=\u001b[39mtrial,\n\u001b[1;32m   2210\u001b[0m         ignore_keys_for_eval\u001b[38;5;241m=\u001b[39mignore_keys_for_eval,\n\u001b[1;32m   2211\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/transformers/trainer.py:2256\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2254\u001b[0m logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCurrently training with a batch size of: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_train_batch_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   2255\u001b[0m \u001b[38;5;66;03m# Data loader and number of training steps\u001b[39;00m\n\u001b[0;32m-> 2256\u001b[0m train_dataloader \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_train_dataloader()\n\u001b[1;32m   2257\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_fsdp_xla_v2_enabled:\n\u001b[1;32m   2258\u001b[0m     train_dataloader \u001b[38;5;241m=\u001b[39m tpu_spmd_dataloader(train_dataloader)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/transformers/trainer.py:1053\u001b[0m, in \u001b[0;36mTrainer.get_train_dataloader\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1050\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_dataset \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1051\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrainer: training requires a train_dataset.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1053\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_dataloader(\n\u001b[1;32m   1054\u001b[0m     dataset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_dataset,\n\u001b[1;32m   1055\u001b[0m     description\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1056\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_train_batch_size,\n\u001b[1;32m   1057\u001b[0m     sampler_fn\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_train_sampler,\n\u001b[1;32m   1058\u001b[0m     is_training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m   1059\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/transformers/trainer.py:1039\u001b[0m, in \u001b[0;36mTrainer._get_dataloader\u001b[0;34m(self, dataset, description, batch_size, sampler_fn, is_training, dataloader_key)\u001b[0m\n\u001b[1;32m   1036\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1037\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_eval_dataloaders \u001b[38;5;241m=\u001b[39m {dataloader_key: dataloader}\n\u001b[0;32m-> 1039\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mprepare(dataloader)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/accelerate/accelerator.py:1360\u001b[0m, in \u001b[0;36mAccelerator.prepare\u001b[0;34m(self, device_placement, *args)\u001b[0m\n\u001b[1;32m   1349\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   1350\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(obj, torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mModule)\n\u001b[1;32m   1351\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverify_device_map(obj)\n\u001b[1;32m   1352\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistributed_type \u001b[38;5;241m!=\u001b[39m DistributedType\u001b[38;5;241m.\u001b[39mNO\n\u001b[1;32m   1353\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m os\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mACCELERATE_BYPASS_DEVICE_MAP\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfalse\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrue\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1354\u001b[0m     ):\n\u001b[1;32m   1355\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1356\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt train a model that has been loaded with `device_map=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m` in any distributed mode.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1357\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Please rerun your script specifying `--num_processes=1` or by launching with `python \u001b[39m\u001b[38;5;124m{{\u001b[39m\u001b[38;5;124mmyscript.py}}`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1358\u001b[0m         )\n\u001b[0;32m-> 1360\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistributed_type \u001b[38;5;241m==\u001b[39m DistributedType\u001b[38;5;241m.\u001b[39mDEEPSPEED:\n\u001b[1;32m   1361\u001b[0m     model_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m   1362\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m args:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/accelerate/accelerator.py:628\u001b[0m, in \u001b[0;36mAccelerator.distributed_type\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    626\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdistributed_type\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 628\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mdistributed_type\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/accelerate/state.py:1195\u001b[0m, in \u001b[0;36mAcceleratorState.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name: \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m   1192\u001b[0m     \u001b[38;5;66;03m# By this point we know that no attributes of `self` contain `name`,\u001b[39;00m\n\u001b[1;32m   1193\u001b[0m     \u001b[38;5;66;03m# so we just modify the error message\u001b[39;00m\n\u001b[1;32m   1194\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_known_attrs:\n\u001b[0;32m-> 1195\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[1;32m   1196\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`AcceleratorState` object has no attribute `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m`. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1197\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis happens if `AcceleratorState._reset_state()` was called and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1198\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124man `Accelerator` or `PartialState` was not reinitialized.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1199\u001b[0m         )\n\u001b[1;32m   1200\u001b[0m     \u001b[38;5;66;03m# Raise a typical AttributeError\u001b[39;00m\n\u001b[1;32m   1201\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAcceleratorState\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: `AcceleratorState` object has no attribute `distributed_type`. This happens if `AcceleratorState._reset_state()` was called and an `Accelerator` or `PartialState` was not reinitialized."
     ]
    }
   ],
   "source": [
    "# Train the Model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 precision    recall  f1-score   support\n",
      "\n",
      "    recommended       1.00      0.99      0.99       144\n",
      "Not recommended       1.00      1.00      1.00       139\n",
      "        Neutral       0.99      1.00      0.99       149\n",
      "\n",
      "       accuracy                           1.00       432\n",
      "      macro avg       1.00      1.00      1.00       432\n",
      "   weighted avg       1.00      1.00      1.00       432\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Get predictions from your trained model\n",
    "predictions = trainer.predict(test_dataset)\n",
    "y_pred = predictions.predictions.argmax(-1)\n",
    "y_true = predictions.label_ids\n",
    "\n",
    "# Define class names\n",
    "target_names = ['recommended', 'Not recommended', 'Neutral']\n",
    "\n",
    "# Print the report\n",
    "print(classification_report(y_true, y_pred, target_names=target_names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./sentiment_model/tokenizer_config.json',\n",
       " './sentiment_model/special_tokens_map.json',\n",
       " './sentiment_model/vocab.txt',\n",
       " './sentiment_model/added_tokens.json',\n",
       " './sentiment_model/tokenizer.json')"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained(\"./sentiment_model\")\n",
    "tokenizer.save_pretrained(\"./sentiment_model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Generate confusion matrix\n",
    "predictions = trainer.predict(test_dataset)\n",
    "preds = np.argmax(predictions.predictions, axis=1)\n",
    "labels = predictions.label_ids\n",
    "\n",
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(labels, preds)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
